{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f5e5464-4d1a-4497-a6c1-0a446773aab4",
   "metadata": {},
   "source": [
    "# Inception score \n",
    "code from: https://machinelearningmastery.com/how-to-implement-the-inception-score-from-scratch-for-evaluating-generated-images/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea383f98-dca6-475d-9b42-5f22ed398bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# calculate inception score for cifar-10 in Keras\n",
    "from math import floor\n",
    "from numpy import ones\n",
    "from numpy import expand_dims\n",
    "from numpy import log\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import exp\n",
    "from numpy.random import shuffle\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.datasets import cifar10\n",
    "from skimage.transform import resize\n",
    "from numpy import asarray\n",
    " \n",
    "# scale an array of images to a new size\n",
    "def scale_images(images, new_shape):\n",
    "\timages_list = list()\n",
    "\tfor image in images:\n",
    "\t\t# resize with nearest neighbor interpolation\n",
    "\t\tnew_image = resize(image, new_shape, 0)\n",
    "\t\t# store\n",
    "\t\timages_list.append(new_image)\n",
    "\treturn asarray(images_list)\n",
    " \n",
    "# assumes images have any shape and pixels in [0,255]\n",
    "def calculate_inception_score(images, n_split=10, eps=1E-16):\n",
    "\t# load inception v3 model\n",
    "\tmodel = InceptionV3()\n",
    "\t# enumerate splits of images/predictions\n",
    "\tscores = list()\n",
    "\tn_part = floor(images.shape[0] / n_split)\n",
    "\tfor i in range(n_split):\n",
    "\t\t# retrieve images\n",
    "\t\tix_start, ix_end = i * n_part, (i+1) * n_part\n",
    "\t\tsubset = images[ix_start:ix_end]\n",
    "\t\t# convert from uint8 to float32\n",
    "\t\tsubset = subset.astype('float32')\n",
    "\t\t# scale images to the required size\n",
    "\t\tsubset = scale_images(subset, (299,299,3))\n",
    "\t\t# pre-process images, scale to [-1,1]\n",
    "\t\tsubset = preprocess_input(subset)\n",
    "\t\t# predict p(y|x)\n",
    "\t\tp_yx = model.predict(subset)\n",
    "\t\t# calculate p(y)\n",
    "\t\tp_y = expand_dims(p_yx.mean(axis=0), 0)\n",
    "\t\t# calculate KL divergence using log probabilities\n",
    "\t\tkl_d = p_yx * (log(p_yx + eps) - log(p_y + eps))\n",
    "\t\t# sum over classes\n",
    "\t\tsum_kl_d = kl_d.sum(axis=1)\n",
    "\t\t# average over images\n",
    "\t\tavg_kl_d = mean(sum_kl_d)\n",
    "\t\t# undo the log\n",
    "\t\tis_score = exp(avg_kl_d)\n",
    "\t\t# store\n",
    "\t\tscores.append(is_score)\n",
    "\t# average across images\n",
    "\tis_avg, is_std = mean(scores), std(scores)\n",
    "\treturn is_avg, is_std\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9eba2fc-ec42-4ba6-b5bc-adb3e153b946",
   "metadata": {},
   "source": [
    "# IS in Cifar 10 from the tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9104d42d-0937-4ee1-ae16-b9da9da1d7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded (50000, 32, 32, 3)\n",
      "32/32 [==============================] - 36s 1s/step\n",
      "32/32 [==============================] - 41s 1s/step\n",
      "32/32 [==============================] - 40s 1s/step\n",
      "32/32 [==============================] - 32s 997ms/step\n",
      "32/32 [==============================] - 32s 982ms/step\n",
      "32/32 [==============================] - 32s 1s/step\n",
      "32/32 [==============================] - 32s 1s/step\n",
      "32/32 [==============================] - 32s 996ms/step\n",
      "32/32 [==============================] - 32s 981ms/step\n",
      "32/32 [==============================] - 31s 965ms/step\n",
      "score 11.081058 0.20513362\n"
     ]
    }
   ],
   "source": [
    "# load cifar10 images\n",
    "(images, _), (_, _) = cifar10.load_data()\n",
    "# shuffle images\n",
    "shuffle(images)\n",
    "print('loaded', images.shape)\n",
    "# calculate inception score\n",
    "is_avg, is_std = calculate_inception_score(images[:10000])\n",
    "print('score', is_avg, is_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a9f93e-2305-4071-a82d-1b49646a8c62",
   "metadata": {},
   "source": [
    "## IS in EM images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "114471fb-4b8f-47d5-9602-9555765ac6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy\n",
    "from PIL import Image\n",
    "# list the images in augmented data\n",
    "perc_train = 0.8\n",
    "N = 1000\n",
    "\n",
    "dirpath = os.getcwd()\n",
    "data_path = os.path.join(dirpath, \"augmented_data\") # read some of the aumented data\n",
    "img_list = numpy.array([filename.split(\".jpg\")[0] for filename in os.listdir(data_path)])\n",
    "# split the data grouping by original image\n",
    "group_list = numpy.array([\"_\".join(filename.split(\"_\")[:2]) for filename in img_list])\n",
    "group_list_un = numpy.unique(group_list)\n",
    "num_train = numpy.round(len(group_list_un)*perc_train).astype('int')\n",
    "numpy.random.seed(seed=2)\n",
    "train_groups = numpy.random.choice(group_list_un, size=num_train, replace=False)\n",
    "train_idx =sum([list(numpy.where(group_list == val)[0]) for val in train_groups], [])\n",
    "test_idx = list(set(range(len(group_list))).difference(set(train_idx)))\n",
    "\n",
    "train_im_list = img_list[train_idx]\n",
    "test_im_list = img_list[test_idx]\n",
    "\n",
    "train_imgs = numpy.array([numpy.asarray(Image.open(os.path.join(data_path, filename + \".jpg\"))) for filename in train_im_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f61c9ec1-6253-4dfd-8dea-fb3f5d4ffd4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded (7680, 256, 256, 3)\n",
      "24/24 [==============================] - 23s 919ms/step\n",
      "24/24 [==============================] - 24s 999ms/step\n",
      "24/24 [==============================] - 24s 1s/step\n",
      "24/24 [==============================] - 24s 1000ms/step\n",
      "24/24 [==============================] - 24s 1s/step\n",
      "24/24 [==============================] - 24s 1s/step\n",
      "24/24 [==============================] - 24s 1s/step\n",
      "24/24 [==============================] - 24s 996ms/step\n",
      "24/24 [==============================] - 25s 1s/step\n",
      "24/24 [==============================] - 25s 1s/step\n",
      "score 3.3171794 0.0733383\n"
     ]
    }
   ],
   "source": [
    "shuffle(train_imgs)\n",
    "print('loaded', train_imgs.shape)\n",
    "# calculate inception score\n",
    "is_avg, is_std = calculate_inception_score(train_imgs)\n",
    "print('score', is_avg, is_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5168135a-2644-4124-9f23-174fedf20891",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
